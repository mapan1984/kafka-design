# 1.6.2 日志清理

日志清理的线程在 `LogManager.startup()` 中启动，具体为：

``` scala
def startup() {
  /* Schedule the cleanup task to delete old logs */
  if (scheduler != null) {
    info("Starting log cleanup with a period of %d ms.".format(retentionCheckMs))
    scheduler.schedule("kafka-log-retention",
                       cleanupLogs _,
                       delay = InitialTaskDelayMs,
                       period = retentionCheckMs,
                       TimeUnit.MILLISECONDS)
    // ....
  }
}
```

间隔 `retentionCheckMs`("log.retention.check.interval.ms") 周期性运行 `LogManager.cleanupLogs()` 方法：

``` scala
/**
 * Delete any eligible logs. Return the number of segments deleted.
 * Only consider logs that are not compacted.
 */
def cleanupLogs(): Unit = {
  debug("Beginning log cleanup...")
  var total = 0
  val startMs = time.milliseconds

  // clean current logs.
  val deletableLogs = {
    if (cleaner != null) {
      // prevent cleaner from working on same partitions when changing cleanup policy
      cleaner.pauseCleaningForNonCompactedPartitions()
    } else {
      currentLogs.filter {
        case (_, log) => !log.config.compact
      }
    }
  }

  try {
    deletableLogs.foreach {
      case (topicPartition, log) =>
        debug(s"Garbage collecting '${log.name}'")
        total += log.deleteOldSegments()

        val futureLog = futureLogs.get(topicPartition)
        if (futureLog != null) {
          // clean future logs
          debug(s"Garbage collecting future log '${futureLog.name}'")
          total += futureLog.deleteOldSegments()
        }
    }
  } finally {
    if (cleaner != null) {
      cleaner.resumeCleaning(deletableLogs.map(_._1))
    }
  }

  debug(s"Log cleanup completed. $total files deleted in " +
                (time.milliseconds - startMs) / 1000 + " seconds")
}
```

调用每一个 log 实例的 `Log.deleteOldSegments()` 方法：

``` scala
  /**
   * Delete any log segments that have either expired due to time based retention
   * or because the log size is > retentionSize
   */
  def deleteOldSegments(): Int = {
    if (!config.delete) return 0
    deleteRetentionMsBreachedSegments() + deleteRetentionSizeBreachedSegments() + deleteLogStartOffsetBreachedSegments()
  }
```

这里实际调用了 3 个方法，分别是：

* deleteRetentionMsBreachedSegments: 按保留时间清理
* deleteRetentionSizeBreachedSegments: 按保留大小清理
* deleteLogStartOffsetBreachedSegments: 清理 start offset 之前的数据，kafka 提供了 `DeleteRecords` API，可以手动修改 topic partition 的 start offset

## deleteRetentionMsBreachedSegments

`Log.scala`

``` scala
private def deleteRetentionMsBreachedSegments(): Int = {
  if (config.retentionMs < 0) return 0
  val startMs = time.milliseconds
  deleteOldSegments((segment, _) => startMs - segment.largestTimestamp > config.retentionMs,
    reason = s"retention time ${config.retentionMs}ms breach")
}
```

这里判断的依据是 `startMs - segment.largestTimestamp > config.retentionMs`

看一下 largestTimestamp 是怎么定义的：

`LogSegment.scala`

``` scala
/**
 * The last modified time of this log segment as a unix time stamp
 */
def lastModified = log.file.lastModified

/**
 * The largest timestamp this segment contains, if maxTimestampSoFar >= 0, otherwise None.
 */
def largestRecordTimestamp: Option[Long] = if (maxTimestampSoFar >= 0) Some(maxTimestampSoFar) else None

/**
 * The largest timestamp this segment contains.
 */
def largestTimestamp = if (maxTimestampSoFar >= 0) maxTimestampSoFar else lastModified
```

消息的最大时间戳或者文件的最后修改时间。

## deleteRetentionSizeBreachedSegments

## deleteLogStartOffsetBreachedSegments

## 收束到 deleteOldSegments

上述 3 种情况，都会收束到 `Log.deleteOldSegments()`，不同的情况只是传不同的 `predicate` 判断方法。

``` scala
/**
 * Delete any log segments matching the given predicate function,
 * starting with the oldest segment and moving forward until a segment doesn't match.
 *
 * @param predicate A function that takes in a candidate log segment and the next higher segment
 *                  (if there is one) and returns true iff it is deletable
 * @return The number of segments deleted
 */
private def deleteOldSegments(predicate: (LogSegment, Option[LogSegment]) => Boolean, reason: String): Int = {
  lock synchronized {
    val deletable = deletableSegments(predicate)
    if (deletable.nonEmpty)
      info(s"Found deletable segments with base offsets [${deletable.map(_.baseOffset).mkString(",")}] due to $reason")
    deleteSegments(deletable)
  }
}
```

遍历所有 segment，用 predicate 判断是否可以删除，返回可以删除 segment 的集合：

``` scala
/**
 * Find segments starting from the oldest until the user-supplied predicate is false or the segment
 * containing the current high watermark is reached. We do not delete segments with offsets at or beyond
 * the high watermark to ensure that the log start offset can never exceed it. If the high watermark
 * has not yet been initialized, no segments are eligible for deletion.
 *
 * A final segment that is empty will never be returned (since we would just end up re-creating it).
 *
 * @param predicate A function that takes in a candidate log segment and the next higher segment
 *                  (if there is one) and returns true iff it is deletable
 * @return the segments ready to be deleted
 */
private def deletableSegments(predicate: (LogSegment, Option[LogSegment]) => Boolean): Iterable[LogSegment] = {
  if (segments.isEmpty || replicaHighWatermark.isEmpty) {
    Seq.empty
  } else {
    val highWatermark = replicaHighWatermark.get
    val deletable = ArrayBuffer.empty[LogSegment]
    var segmentEntry = segments.firstEntry
    while (segmentEntry != null) {
      val segment = segmentEntry.getValue
      val nextSegmentEntry = segments.higherEntry(segmentEntry.getKey)
      val (nextSegment, upperBoundOffset, isLastSegmentAndEmpty) = if (nextSegmentEntry != null)
        (nextSegmentEntry.getValue, nextSegmentEntry.getValue.baseOffset, false)
      else
        (null, logEndOffset, segment.size == 0)

      if (highWatermark >= upperBoundOffset && predicate(segment, Option(nextSegment)) && !isLastSegmentAndEmpty) {
        deletable += segment
        segmentEntry = nextSegmentEntry
      } else {
        segmentEntry = null
      }
    }
    deletable
  }
}
```

``` scala
private def deleteSegments(deletable: Iterable[LogSegment]): Int = {
  maybeHandleIOException(s"Error while deleting segments for $topicPartition in dir ${dir.getParent}") {
    val numToDelete = deletable.size
    if (numToDelete > 0) {
      // we must always have at least one segment, so if we are going to delete all the segments, create a new one first
      if (segments.size == numToDelete)
        roll()
      lock synchronized {
        checkIfMemoryMappedBufferClosed()
        // remove the segments for lookups
        deletable.foreach(deleteSegment)
        maybeIncrementLogStartOffset(segments.firstEntry.getValue.baseOffset)
      }
    }
    numToDelete
  }
}
```

`Log.scala`


``` scala
 /**
   * If topic deletion is enabled, delete any log segments that have either expired due to time based retention
   * or because the log size is > retentionSize.
   *
   * Whether or not deletion is enabled, delete any log segments that are before the log start offset
   */
  def deleteOldSegments(): Int = {
    if (config.delete) {
      deleteRetentionMsBreachedSegments() + deleteRetentionSizeBreachedSegments() + deleteLogStartOffsetBreachedSegments()
    } else {
      deleteLogStartOffsetBreachedSegments()
    }
  }

  private def deleteRetentionMsBreachedSegments(): Int = {
    if (config.retentionMs < 0) return 0
    val startMs = time.milliseconds

    def shouldDelete(segment: LogSegment, nextSegmentOpt: Option[LogSegment]): Boolean = {
      startMs - segment.largestTimestamp > config.retentionMs
    }

    deleteOldSegments(shouldDelete, RetentionMsBreach)
  }
```
